{
	"link":"http://community.topcoder.com/stat?c=problem_statement&pm=176&rd=4003",
	"statement":"<pre>Class name: NeuralNet\nMethod name: testTraining\nParameters: int[], int[], int[]\nReturns: int[]\n\nYou will create a Neural Network.  A Neural Network is used to learn patterns\nand relationships in data.  You will train a network with training inputs,\nin[].  Once you have trained your network to return the expected training\noutputs, out[], send a set of test inputs, testIn[], through the network and\nreturn that output as your result.\n\nThe method signature is (be sure your method is declared public):\nint[] testTraining(int[] in, int[] out, int[] testIn)\n\nFor the purpose of this problem, the neural network contains four nodes.  Each\nnode takes the int array in[] that contains four elements as input and produces\nan int output.  Stored within each node is float array, which contains weights,\nw[].  Each element of the weight array is assigned to the element of the same\nindex of the input array.  For example, if in[0]=1 and w[0]=.5 then in[0] has a\nweight of .5 assigned to it.  Each node also has a threshold value, th.\n\nThe output of the node is calculated by multiplying each input by its\ncorresponding weight, and summing all these values.  If the resulting value is\ngreater than or equal to the threshold value, then node outputs a value of 1,\notherwise, it outputs a 0. For example,\n\nin[0]    -----------------\n         |               |\nin[1]    |               |\n---&gt;|    Node 1     | ---&gt;  x = in[0]*w[0] + in[1]*w[1] + in[2]*w[2] +\nin[3]*w[3]\n         |               |       if x &gt;= th then out1 = 1  else  out1 = 0\nin[2]    |      w[]      |\n         |               |\nin[3]    |_______________|\n\n\nin[0]    -----------------\n         |               |\nin[1]    |               |\n---&gt;|    Node 2     | ---&gt;  x = in[0]*w[0] + in[1]*w[1] + in[2]*w[2] +\nin[3]*w[3]\n         |               |       if x &gt;= th then out2 = 1  else  out2 = 0\nin[2]    |      w[]      |\n         |               |\nin[3]    |_______________|\n\n\nin[0]    -----------------\n         |               |\nin[1]    |               |\n---&gt;|    Node 3     | ---&gt;  x = in[0]*w[0] + in[1]*w[1] + in[2]*w[2] +\nin[3]*w[3]\n         |               |       if x &gt;= th then out3 = 1  else  out3 = 0\nin[2]    |      w[]      |\n         |               |\nin[3]    |_______________|\n\n\nin[0]    -----------------\n         |               |\nin[1]    |               |\n---&gt; |    Node 4     | ---&gt;  x = in[0]*w[0] + in[1]*w[1] + in[2]*w[2] +\nin[3]*w[3]\n         |               |       if x &gt;= th then out4 = 1  else  out4 = 0\nin[2]    |      w[]      |\n         |               |\nin[3]    |_______________|\n\n\nTopCoder will enforce the following rules:\n\n*All arrays used for input into the method are of length 4\n\n*The elements of the three input arrays to the method are always 1 or 0.\n\n\nNotes:\n\nThe initial value of all the weights in all the nodes will be 0.25.\nThe threshold value will be the same for all nodes and will be 0.5.\nEvery array in this problem begins at index zero.\nThe delta value (described below) is always equal to 0.10\n\nThe value of this neural net is that it can train itself by changing its\ninternal weights when given an input and the expected output.\nThe training of a single node is described as follows:\n\n\n- First, set a &quot;delta&quot; value.  This value is the same all the time, and should\nbe hard-coded in this problem to 0.10\n\n- Compare the output values of each node to its corresponding element in the\noutput array.  If they do not match, the internal weights of the node that did\nnot match must be adjusted.  Adjust the internal weights with a constant\n&quot;delta&quot; of 0.1 in the following fashion:\n\n1) if the output matches the expected output, do nothing.\n2) if the output is 1, and expected is 0, subtract the &quot;delta&quot; value 0.1 from\nthe weights that correspond to the inputs that had a value of 1\n(If an input was 0, it did not contribute to the output, so its weight should\nnot be adjusted).\n3) if the output is 0, and the expected is 1, add the &quot;delta&quot; value 0.1 to the\nweights that correspond to the inputs that had a value of 1.\n\n- Continue to run the set of inputs through the nodes and making these\nadjustments until your outputs match the desired outputs.\n\nNOTE:  If, for some reason, you determine that the net is untrainable (i.e., if\ninput is all zeroes, there is no way to produce any output values which are\nnon-zero) do not train.\n\nTesting the Trained Neural Network:\n\nOnce you have trained your Neural Network, you will utilize the third argument\nof test inputs and return the outputs as your result.\n\nCreate a method testTraining that takes three int[], representing the node\ninputs, the expected outputs and a test case.  The method should return an\nint[] that represents the output of the test case after the neural net is\ntrained.\n\nExample 1: (w1[0] means the weight associated with input 0 in node 1)\n\ntrainingInputs = { 1, 0, 0, 0 }, trainingOutputs = { 0, 0, 1, 0 }, testInputs =\n{ 0, 1, 1, 0 }\n\nThe initial values of the weights (w[i]) are 0.25\n\nAfter entering { 1, 0, 0, 0 } as inputs,The Outputs are:\n\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0), and\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0)\n\nNode 0 generates the correct output, so leave it alone.\nNode 1 generates the correct output, so leave it alone.\nNode 2 does not, so adjust the weights of Node 2:\n\ni[0] = 1 so we can adjust w2[0]: w2[0] = w2[0] + &quot;delta&quot; -- or -- w2[0] = 0.25\n+ 0.1 = 0.35 (+ because the current output is too low)\ni[1] = 0 so we do not adjust w2[1].\ni[2] = 0 so we do not adjust w2[2].\ni[3] = 0 so we do not adjust w2[3].\n\nNode 3 generates the correct output, so leave it alone.\n\nAfter this round of training, the Outputs are:\n\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0), \n(1 * 0.35 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.35 -----&gt; 0), and\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0)\n\nand Node 2 still does not generate the correct output, so adjust the weights of\nNode 2:\n\ni[0] = 1 so we can adjust w2[0]: w2[0] = w2[0] + &quot;delta&quot; -- or -- w2[0] = 0.35\n+ 0.1 = 0.45 (+ because the current output is too low)\ni[1] = 0 so we do not adjust w2[1].\ni[2] = 0 so we do not adjust w2[2].\ni[3] = 0 so we do not adjust w2[3].\n\nAfter this round of training, the Outputs are:\n\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0), \n(1 * 0.45 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.45 -----&gt; 0), and\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0)\n\nand Node 2 still does not generate the correct output, so adjust the weights of\nNode 2:\n\ni[0] = 1 so we can adjust w2[0]: w2[0] = w2[0] + &quot;delta&quot; -- or -- w2[0] = 0.45\n+ 0.1 = 0.55 (+ because the current output is too low)\ni[1] = 0 so we do not adjust w2[1].\ni[2] = 0 so we do not adjust w2[2].\ni[3] = 0 so we do not adjust w2[3].\n\nAfter this round of training, the Outputs are:\n\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0), \n(1 * 0.55 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.55 -----&gt; 1), and\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0)\n\nAnd the outputs are the same as the desired outputs.\n\nNow we input the elements of testInput into the net and the Outputs are:\n\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1), \n(0 * 0.55 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1), and\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1)\n\nreturn { 1, 1, 1, 1 }\n\nExample 2: trainingInputs = { 0, 1, 1, 1 } trainingOutputs = { 1, 1, 1, 1 }\ntestInputs = { 1, 0, 1, 0 }\n\nThe initial values of the weights (w[i]) are 0.25. After entering { 0, 1, 1, 1\n} as inputs, The Outputs are:\n\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 1 * 0.25 = 0.75 -----&gt; 1),\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 1 * 0.25 = 0.75 -----&gt; 1),\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 1 * 0.25 = 0.75 -----&gt; 1), and\n(0 * 0.25 + 1 * 0.25 + 1 * 0.25 + 1 * 0.25 = 0.75 -----&gt; 1)\n\nAll nodes generate the correct output, so we do not train,\n\nNow we input the elements of testInput into the net and the Outputs are:\n\n(1 * 0.25 + 0 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(1 * 0.25 + 0 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(1 * 0.25 + 0 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1), and\n(1 * 0.25 + 0 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1)\n\nreturn { 1, 1, 1, 1 }\n\n\nExample 3: trainingInputs = { 1, 1, 0, 0 } trainingOutputs = { 1, 1, 1, 0 }\ntestInputs = { 1, 1, 1, 0 }\n\nThe initial values of the weights (w[i]) are 0.5. After entering { 1, 1, 0, 0 }\nas inputs, the Output is:\n\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1), and\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1)\n\nNode 3 is producing the wrong output. Adjust Node 3:\n\ni[0] = 1 so we adjust w3[0]: w3[0] = w3[0] - &quot;delta&quot; -- or -- w3[0] = w3[0] -\n0.1 = 0.25 - 0.1 = 0.15  (- because the current output is too low)\ni[1] = 1 so we adjust w3[1]: w3[1] = w3[1] - &quot;delta&quot; -- or -- w3[1] = w3[1] -\n0.1 = 0.25 - 0.1 = 0.15 (- because the current output is too low)\ni[2] = 0 so we do not adjust its corresponding weight.\ni[3] = 0 so we do not adjust its corresponding weight.\n\nAfter this round of training, the Outputs are:\n\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1),\n(1 * 0.25 + 1 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.5 -----&gt; 1), and\n(1 * 0.15 + 1 * 0.15 + 0 * 0.25 + 0 * 0.25 = 0.3 -----&gt; 0)\n\nand we have the desired output. Now we input the elements of testInput into the\nnet and the Outputs are:\n\n(1 * 0.25 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.75 -----&gt; 1),\n(1 * 0.25 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.75 -----&gt; 1),\n(1 * 0.25 + 1 * 0.25 + 1 * 0.25 + 0 * 0.25 = 0.75 -----&gt; 1), and\n(1 * 0.15 + 1 * 0.15 + 1 * 0.25 + 0 * 0.25 = 0.55 -----&gt; 1)\n\nreturn { 1, 1, 1, 1 }\n\n\nExample 4: trainingInputs = { 0, 0, 0, 0 } trainingOutputs = { 1, 1, 0, 1 }\ntestInputs = { 1, 0, 0, 0 }\n\nSince all inputs are zero, we cannot train the net.  Hence, we input the\nelements of testInput into the net and the Outputs are:\n\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0),\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0), and\n(1 * 0.25 + 0 * 0.25 + 0 * 0.25 + 0 * 0.25 = 0.25 -----&gt; 0)\n\nreturn { 0, 0, 0, 0 }\n\n</pre>",
	"notes":[],
	"definition":[
		{
			"definitionKey":"Class:",
			"definitionVal":"NeuralNet",
			"order":1
		},
		{
			"definitionKey":"Method:",
			"definitionVal":"testTraining",
			"order":2
		},
		{
			"definitionKey":"Parameters:",
			"definitionVal":"int[], int[], int[]",
			"order":3
		},
		{
			"definitionKey":"Returns:",
			"definitionVal":"int[]",
			"order":4
		},
		{
			"definitionKey":"Method signature:",
			"definitionVal":"int[] testTraining(int[] param0, int[] param1, int[] param2)",
			"order":5
		}
	],
	"examples":[],
	"constraints":[]
}